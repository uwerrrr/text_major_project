{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "VeAj9BvxrwKh",
        "GocBgeGN3EMq",
        "qqr1slE-v8vl",
        "EjyhnqtbuHgy",
        "AqrnszOsbPL2",
        "Xz2aY3h0-RB8",
        "y3frxHcF-uxA",
        "pvNhlg4iTqzS",
        "LSIJYc-TX0hu",
        "7ITbYby-8gFd",
        "5bGAczUOd_vh",
        "KSjjLIj0Zt8y",
        "Z5gM_vsjW88T",
        "RMd018-A-KpC",
        "Pwq6jYZIrGgU",
        "wZLFeg1eTSP3",
        "GFqsSZPrTZDL",
        "HFV-pT9xVant",
        "wMY3biLHn8Ae",
        "G0mcw7kqlApu"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/uwerrrr/text_major_project/blob/main/45817006_text_major_project.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9BHxRrjZQEj"
      },
      "source": [
        "# Introduction\n",
        "\n",
        "This notebook is for the major project submission for COMP8220, on the **language** dataset and task.  It contains the following main sections:\n",
        "\n",
        "*   Preparation\n",
        "*   Data transformation\n",
        "*   Conventional ML models\n",
        "*   Deep learning models\n",
        "*   Discussion of Model Performance and Implementation\n",
        "\n",
        "\n",
        "**Note:**\n",
        "\n",
        "\n",
        "*   Each model section also contains observation part at the end which highlights my observation from the process of training the models.\n",
        "*   Since this notebook is lengthy, it is suggested to use table of content sidebar for better navigation.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VeAj9BvxrwKh"
      },
      "source": [
        "# Preparation\n",
        "\n",
        "This section contains loading data into the notebook and some slight raw data exploration"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhIUlBiJeSjq",
        "outputId": "60d0eb4a-03b5-4c92-d8c2-877c244ccbbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMaUgLJtr15X",
        "outputId": "f4fae8d8-ecd3-47e8-9bbc-205dc62511ff",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import os\n",
        "\n",
        "os.chdir('./gdrive/MyDrive/Colab Notebooks/Project/')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['45817006_text_major_project.ipynb',\n",
              " 'Project desc.pdf',\n",
              " ' Image Dataset Details.pdf',\n",
              " 'Language Dataset Desc.pdf',\n",
              " 'Code Snippets',\n",
              " 'datasets',\n",
              " '.ipynb_checkpoints',\n",
              " 'test',\n",
              " 'models',\n",
              " '45817006-conv.csv',\n",
              " 'glove.twitter.27B',\n",
              " 'text_code_stub.ipynb',\n",
              " 'model_3_2_best.h5',\n",
              " '45817006-private.csv',\n",
              " '45817006-deep.csv',\n",
              " 'sample-notebook-template.ipynb',\n",
              " 'Copy of 45817006_text_major_project.ipynb',\n",
              " 'best_model.h5']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports\n",
        "import numpy as np\n",
        "import os\n",
        "import pickle\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "from keras import backend\n",
        "\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.stem.porter import *\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "import keras.optimizers\n",
        "from keras.utils import np_utils, to_categorical\n",
        "from keras.models import Sequential, load_model\n",
        "from keras.optimizers import Adadelta, Adam, RMSprop\n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from keras.layers import Dense, Input, TimeDistributed, Dropout, Conv1D, MaxPooling1D\n",
        "from keras.layers import LSTM, SimpleRNN, Bidirectional, Masking, Activation, GRU\n",
        "from keras.layers import Flatten, BatchNormalization, Embedding\n",
        "from keras.preprocessing import sequence, text, sequence\n",
        "from keras.preprocessing.text import Tokenizer, one_hot\n",
        "from keras.utils import pad_sequences\n",
        "\n",
        "from tensorflow.keras import regularizers\n",
        "\n",
        "import fastai\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from functools import partial\n",
        "import io\n",
        "\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BaB8QGdWfYeD",
        "outputId": "73d4e712-beac-4783-d12b-e87141dea424"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I1XD4gUUWsN"
      },
      "source": [
        "### Load data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRVgtkPlUnuP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2eb0a767-c028-4135-d7d1-4d5f20344c05"
      },
      "source": [
        "def load_pickle(path):\n",
        "    with open(path, 'rb') as f:\n",
        "        file = pickle.load(f)\n",
        "        print ('Loaded %s..' %path)\n",
        "        return file\n",
        "\n",
        "dataset_directory = 'datasets/text-data/'  ## CHANGE TO YOUR OWN DIRECTORY\n",
        "\n",
        "emotions = ['anger', 'fear', 'joy', 'sadness']\n",
        "\n",
        "tweets_train = np.load(join(dataset_directory, 'text_train_tweets.npy'))\n",
        "labels_train = np.load(join(dataset_directory, 'text_train_labels.npy'))\n",
        "vocabulary = load_pickle(join(dataset_directory, 'text_word_to_idx.pkl'))\n",
        "\n",
        "tweets_val = np.load(join(dataset_directory, 'text_val_tweets.npy'))\n",
        "labels_val = np.load(join(dataset_directory, 'text_val_labels.npy'))\n",
        "\n",
        "tweets_test_public = np.load(join(dataset_directory, 'text_test_public_tweets_rand.npy'))\n",
        "tweets_test_private = np.load(join(dataset_directory, 'text_test_private_tweets.npy'))\n",
        "\n",
        "print(len(vocabulary))\n",
        "idx_to_word = {i: w for w, i in vocabulary.items()}\n",
        "for i in range(7):\n",
        "  print(i, idx_to_word[i])\n",
        "\n",
        "sample = 4  ## YOU CAN TRY OUT OTHER TWEETS\n",
        "\n",
        "print('sample tweet, stored form:')\n",
        "print(tweets_train[sample])\n",
        "print(labels_train[sample])\n",
        "\n",
        "print('sample tweet, readable form:')\n",
        "decode = []\n",
        "for i in range(50):\n",
        "  decode.append(idx_to_word[tweets_train[sample][i]])\n",
        "print(decode)\n",
        "print(emotions[labels_train[sample]])\n",
        "\n",
        "\n",
        "print('shape of tweets_train:', tweets_train.shape)\n",
        "print('shape of labels_train:',labels_train.shape)\n",
        "print('shape of tweets_val:',tweets_val.shape)\n",
        "print('shape of labels_val:',labels_val.shape)\n",
        "print('shape of tweets_test_public:',tweets_test_public.shape)\n",
        "print('shape of tweets_test_private:',tweets_test_private.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded datasets/text-data/text_word_to_idx.pkl..\n",
            "13978\n",
            "0 <NULL>\n",
            "1 <START>\n",
            "2 <END>\n",
            "3 it\n",
            "4 makes\n",
            "5 me\n",
            "6 so\n",
            "sample tweet, stored form:\n",
            "[ 1 57 74 36 75 76 77 78 29 79 47 80 81 77 82 29 38 36 83 84 85 77 86  2\n",
            "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
            "  0  0  0  0]\n",
            "0\n",
            "sample tweet, readable form:\n",
            "['<START>', 'i', 'need', 'a', 'üç±', 'sushi', 'date', 'üçô', '<user>', 'üçù', 'an', 'olive', 'guarded', 'date', 'üßÄ', '<user>', 'and', 'a', 'üëä', 'üèº', 'rockys', 'date', 'üçï', '<END>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>', '<NULL>']\n",
            "anger\n",
            "shape of tweets_train: (7098, 52)\n",
            "shape of labels_train: (7098,)\n",
            "shape of tweets_val: (1460, 52)\n",
            "shape of labels_val: (1460,)\n",
            "shape of tweets_test_public: (4064, 52)\n",
            "shape of tweets_test_private: (4257, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oopVdFk0dFVm"
      },
      "source": [
        "## Data exploration"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ga1VqoQnkCLp"
      },
      "source": [
        "# transform to dataframe\n",
        "df_labels_train = pd.DataFrame(labels_train)\n",
        "df_labels_train.columns = ['labels']\n",
        "\n",
        "# add emotion to df\n",
        "emotion_labels = []\n",
        "for i in df_labels_train.index:\n",
        "  emotion_labels.append(emotions[labels_train[i]])\n",
        "\n",
        "df_labels_train[\"emotions\"] = emotion_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiXNLTsQlRIi"
      },
      "source": [
        "**Plot train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S3dxJXE7iy_Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "outputId": "cc22bd27-670c-4d40-a840-661909ab7e4f"
      },
      "source": [
        "df_labels_train.emotions.value_counts().plot(kind='pie', autopct='%1.0f%%',\n",
        "                                         colors=[\"red\", \"yellow\", \"green\",\"blue\"])\n",
        "\n",
        "print(emotions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anger', 'fear', 'joy', 'sadness']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YA0Y9R4RH4_B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "574f755a-5f19-4c25-f330-9980361318ec"
      },
      "source": [
        "print('counts of 4 labels: ')\n",
        "df_labels_train.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts of 4 labels: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2251\n",
              "0    1700\n",
              "2    1615\n",
              "3    1532\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sPeVQZXDDbnV"
      },
      "source": [
        "-> Beside the fact that the number of *fear* tweet is higher than other emotions roughly 10%, the data is not very imbalanced."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gmyOBlTJ3fF7"
      },
      "source": [
        "**Checking the distribution of training set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7sy-HIu3su4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e25206d0-5492-4def-bfc0-418829fd7d84"
      },
      "source": [
        "print(\"labels of the first 10 sentences: \",labels_train[:10])\n",
        "print(\"labels of the last 10 sentences: \",labels_train[len(labels_train)-10:len(labels_train)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels of the first 10 sentences:  [0 0 0 0 0 0 0 0 0 0]\n",
            "labels of the last 10 sentences:  [3 3 3 3 3 3 3 3 3 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3q2bJ1tb5dcB"
      },
      "source": [
        "=> It is clearly that the training data is **sorted** and **not random**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ixx6W4UsfE1t"
      },
      "source": [
        "---\n",
        "# Transformation\n",
        "\n",
        "According to the previous data exploration, the raw data is not random. Therefore, I decided to merge the raw data and split them into new train and validataion sets.\n",
        "\n",
        "This section also contains text converting and cleaning process.\n",
        "Because the given data still contains special characteristics such as emojis and `<words>`, I choose to convert the given data to text and remove all special characteristics and `<words>`.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9pBUMl_nBZPu"
      },
      "source": [
        "random_state = 42"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ZtucaNnBF4s"
      },
      "source": [
        "### Merge and split train and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TD78Zr-sIHW3"
      },
      "source": [
        "tweets_new = np.concatenate((tweets_train, tweets_val))\n",
        "labels_new = np.concatenate((labels_train, labels_val))\n",
        "tweets_train_new, tweets_val_new, labels_train_new, labels_val_new = train_test_split(tweets_new, labels_new, test_size=0.15, random_state = random_state)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LDkSpbaPA7P_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d876db40-5e2a-4757-c133-9613b229028b"
      },
      "source": [
        "print(\"labels of the first 10 sentences: \",labels_train_new[:10])\n",
        "print(\"labels of the last 10 sentences: \",labels_train_new[len(labels_train_new)-10:len(labels_train_new)])\n",
        "print(\"shape of labels_train_new:\",labels_train_new.shape)\n",
        "print(\"shape of tweets_train_new:\",tweets_train_new.shape)\n",
        "print('The first 10 sentences:')\n",
        "tweets_train_new[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels of the first 10 sentences:  [0 1 0 0 1 2 3 2 2 3]\n",
            "labels of the last 10 sentences:  [3 3 2 0 3 3 2 2 0 0]\n",
            "shape of labels_train_new: (7274,)\n",
            "shape of tweets_train_new: (7274, 52)\n",
            "The first 10 sentences:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    1,    29,    57,  1260,  1261,   997,   998,    97,   460,\n",
              "         1262,     2,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,    64,    93,    36,   944,   532,   406,     2,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,   371,   205,   896,    20,   458,    51,  3024,  3025,\n",
              "          122,   877,    26,   739,  3026,    35,    20,   733,    19,\n",
              "           36,  3027,    50,  3028,   113,   115,    36,  1441,   115,\n",
              "            2,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,    29,    29,   126,  3636,    94,   132,   478,    47,\n",
              "         5304,  3032,  4156,     2,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,    29,  3794,  2044,  8988,    94,    36,  8911,    35,\n",
              "           20,  6362,  2862,  8989,   322,  1227,   621,    46,   322,\n",
              "         1227,  8990,  8991,     2,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,  1178,   252,   205,   519,  9351,    38,  8752,  9352,\n",
              "          408,    11,  9353,  1182,  4438,  9354,  9355,     2,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,  5267, 12322,  1983,   534,   192,     6, 12323,     2,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,    20,   776,   730,   115,    33,   173,     9,    11,\n",
              "          132,  9389,   140,    35,   215,  9390,   786,    35,   215,\n",
              "          456,    38,   436,    64,   251,     5,   914,  5927,  9391,\n",
              "         7721,     2,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,   419,    64,   250,    74,   132,   797,    36,  6083,\n",
              "         1399,   115,  7484,   132,  2658,  3357,    51,   432,    52,\n",
              "           53,   330,    74,   132,   142,   516, 10926,     2,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0],\n",
              "       [    1,    29,    29,   200, 11827,   102,    36,  3365,  5870,\n",
              "          118,    20,  2757,    38,    20,   748,    44,   631,   907,\n",
              "         1544,   182,   663,   132,   702,  4945,   122,  2103,  2115,\n",
              "         3302,     2,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HVWfaPmcVpGy"
      },
      "source": [
        "#### Check data balance\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfZz67TQVpG0"
      },
      "source": [
        "# transform to dataframe\n",
        "df_labels_train_new = pd.DataFrame(labels_train_new)\n",
        "df_labels_train_new.columns = ['labels']\n",
        "\n",
        "# add emotion to df\n",
        "emotion_labels = []\n",
        "for i in df_labels_train_new.index:\n",
        "  emotion_labels.append(emotions[labels_train_new[i]])\n",
        "\n",
        "df_labels_train_new[\"emotions\"] = emotion_labels"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "49pX6P2bVpG5"
      },
      "source": [
        "**Plot train data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uNQmS72VVpG5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "62820770-2c6f-4b0b-9f03-cf8b6d36e508"
      },
      "source": [
        "df_labels_train_new.emotions.value_counts().plot(kind='pie', autopct='%1.0f%%',\n",
        "                                         colors=[\"red\", \"yellow\", \"green\",\"blue\"])\n",
        "\n",
        "print(emotions)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['anger', 'fear', 'joy', 'sadness']\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ktG2lrz2VpG7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f3706fb-822a-4a06-b0a0-8bfb5c3737e8"
      },
      "source": [
        "print('counts of 4 labels: ')\n",
        "df_labels_train_new.labels.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "counts of 4 labels: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    2270\n",
              "0    1758\n",
              "3    1625\n",
              "2    1621\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kwdi0agdW51d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "36134107-438e-447e-d1c8-ba5e92dbbf5e"
      },
      "source": [
        "print(\"labels of the first 10 sentences: \",labels_train_new[:10])\n",
        "print(\"labels of the last 10 sentences: \",labels_train_new[len(labels_train_new)-10:len(labels_train_new)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels of the first 10 sentences:  [0 1 0 0 1 2 3 2 2 3]\n",
            "labels of the last 10 sentences:  [3 3 2 0 3 3 2 2 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2LiFs3BbVpG9"
      },
      "source": [
        "#### Observation\n",
        "\n",
        "After merging and splitting, new data shows same degree of balance as the original data.\n",
        "\n",
        "The new data also shows randomness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PifO3dBRgvhZ"
      },
      "source": [
        "### Converting to text\n",
        "\n",
        "Convert all data set to list containing sentences"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dOAXD6SxDn6"
      },
      "source": [
        "# function to convert a set to text\n",
        "def convert_to_text(set):\n",
        "  texts = []\n",
        "  idx = len(set)\n",
        "  vocab_list = list(vocabulary.keys())\n",
        "  for i_t in range(idx):\n",
        "    decode = []\n",
        "    c_t = set[i_t]\n",
        "    for w in range(52):\n",
        "      if c_t[w] > 2: #or c_t[w]==0:      # not include <START> and <END> tags\n",
        "        decode.append(vocab_list[c_t[w]])\n",
        "    texts.append(decode)\n",
        "  # texts=np.array(texts)\n",
        "  # texts=np.array([np.array(xi) for xi in texts])\n",
        "\n",
        "  # return texts\n",
        "\n",
        "  text_set =[]\n",
        "  for i in range(len(texts)):\n",
        "    sen = ' '.join(word for word in texts[i])\n",
        "    text_set.append(sen)\n",
        "\n",
        "  return text_set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OafjHn8T-nJW"
      },
      "source": [
        "tweets_train_t = convert_to_text(tweets_train_new)\n",
        "tweets_val_t = convert_to_text(tweets_val_new)\n",
        "tweets_test_public_t = convert_to_text(tweets_test_public)\n",
        "tweets_test_private_t = convert_to_text(tweets_test_private)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "loCXAJcz5bf0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c7c1c73-4fb0-4235-ef6c-5de6b4f7e09b"
      },
      "source": [
        "print('type of tweets_train_t:', type(tweets_train_t[:5]))\n",
        "print('The first 10 sentences:')\n",
        "tweets_train_t[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of tweets_train_t: <class 'list'>\n",
            "The first 10 sentences:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<user> i accidetly dumped boiling water my myself üò´',\n",
              " 'you are a terrible time üòÇ',\n",
              " 'did we miss the fact that #burkeramsey swung & hit his sister #jonbenet in the face with a golf club previously out of a fit of',\n",
              " '<user> <user> very heading not to mention an agenda driven article',\n",
              " '<user> horrible service ewr not a cloud in the sky normal departure at <time> now leaving at <time> crappy #unitedairlines',\n",
              " '‚Äú when we give cheerfully and accept gratefully everyone is blessed ‚Äù ‚Äï maya angelou',\n",
              " 'ffs clan seriously never been so disheartened',\n",
              " 'the best part of this day jesus is to snuggle up in your embraceto rest in your arms and know you love me üíô ‚ù§ #sweetembrace #delight',\n",
              " \"sometimes you just need to eat a delicious piece of chocolate to remind yourself that there ' s no need to be bitter sweetness\",\n",
              " '<user> <user> trump presidency - a dark age for the usa and the world he would most definitely take us to war short & long term pain']"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OwAvyhmrhQLb"
      },
      "source": [
        "### Cleaning text sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H6Ods91-gW2o"
      },
      "source": [
        "# Function to remove all the special characters\n",
        "import string\n",
        "\n",
        "def clean(set):\n",
        "  processed_features = []\n",
        "\n",
        "\n",
        "  for sentence in range(0, len(set)):\n",
        "\n",
        "\n",
        "    # remove <words>\n",
        "    processed_feature = re.sub(r'<[a-zA-Z0-9]+>', ' ', str(set[sentence]))\n",
        "\n",
        "    # Remove all the special characters\n",
        "    processed_feature = re.sub(r'\\W', ' ', processed_feature)\n",
        "\n",
        "    # remove some special characters\n",
        "    processed_feature = re.sub(r\"[!#$%‚Ä¢&\\'()*+,-./:;=?‚Äú‚Äù_^\\\\`{|}~]\", \" \", processed_feature)\n",
        "\n",
        "    # remove all single characters\n",
        "    processed_feature = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "\n",
        "    # Remove single characters from the start\n",
        "    processed_feature = re.sub(r'\\^[a-zA-Z]\\s+', ' ', processed_feature)\n",
        "\n",
        "    # Substituting multiple spaces with single space\n",
        "    processed_feature = re.sub(r'\\s+', ' ', processed_feature, flags=re.I)\n",
        "\n",
        "    # Converting to Lowercase\n",
        "    processed_feature = processed_feature.lower()\n",
        "\n",
        "    processed_features.append(processed_feature)\n",
        "\n",
        "  return processed_features"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wtb8xjYHieJ6"
      },
      "source": [
        "processed_tweets_train_t = clean(tweets_train_t)\n",
        "processed_tweets_val_t = clean(tweets_val_t)\n",
        "processed_tweets_test_public_t = clean(tweets_test_public_t)\n",
        "processed_tweets_test_private_t = clean(tweets_test_private_t)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wx2lsMDw6-U-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6ec6677-8772-41c1-95ed-b931f28a7141"
      },
      "source": [
        "print('type of tweets_train_t:', type(processed_tweets_train_t[:5]))\n",
        "print('The first 10 sentences:')\n",
        "processed_tweets_train_t[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "type of tweets_train_t: <class 'list'>\n",
            "The first 10 sentences:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[' accidetly dumped boiling water my myself ',\n",
              " 'you are terrible time ',\n",
              " 'did we miss the fact that burkeramsey swung hit his sister jonbenet in the face with golf club previously out of fit of',\n",
              " ' very heading not to mention an agenda driven article',\n",
              " ' horrible service ewr not cloud in the sky normal departure at now leaving at crappy unitedairlines',\n",
              " ' when we give cheerfully and accept gratefully everyone is blessed maya angelou',\n",
              " 'ffs clan seriously never been so disheartened',\n",
              " 'the best part of this day jesus is to snuggle up in your embraceto rest in your arms and know you love me sweetembrace delight',\n",
              " 'sometimes you just need to eat delicious piece of chocolate to remind yourself that there no need to be bitter sweetness',\n",
              " ' trump presidency dark age for the usa and the world he would most definitely take us to war short long term pain']"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDin5RVGbVm4"
      },
      "source": [
        "---\n",
        "# Conventional machine learning\n",
        "\n",
        "For conventional machine learning, I will use TF.IDF method to vectorize the cleaned texts before feeding them to the models.\n",
        "\n",
        "I choose 4 conventional models to compare their efficiency.\n",
        "\n",
        "1.   Naive Bayes Classifier\n",
        "2.   Random Forest Classifier\n",
        "3.   Logistic Regression model\n",
        "4.   LinearSVC model\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GocBgeGN3EMq"
      },
      "source": [
        "### TF.IDF - vectorzing text data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zexrxtXojji7"
      },
      "source": [
        "vectorizer = TfidfVectorizer (\n",
        "                              stop_words=stopwords.words('english')\n",
        "                              )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxGEqB2gkD4g"
      },
      "source": [
        "tfidf_tweets_train = vectorizer.fit_transform(processed_tweets_train_t).toarray()\n",
        "tfidf_tweets_val = vectorizer.transform(processed_tweets_val_t).toarray()\n",
        "tfidf_tweets_test_public = vectorizer.transform(processed_tweets_test_public_t).toarray()\n",
        "tfidf_tweets_test_private = vectorizer.transform(processed_tweets_test_private_t).toarray()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tah01n4TFS5Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "31bdbb80-c688-4ef9-e725-e8d96f6f7478"
      },
      "source": [
        "print('shape of tfidf_tweets_train:', tfidf_tweets_train.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of tfidf_tweets_train: (7274, 11481)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qqr1slE-v8vl"
      },
      "source": [
        "## Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRnEHtIWwBYY"
      },
      "source": [
        "X_train = tfidf_tweets_train\n",
        "y_train = labels_train_new\n",
        "\n",
        "X_val = tfidf_tweets_val\n",
        "y_val = labels_val_new\n",
        "\n",
        "X_test = tfidf_tweets_test_public\n",
        "# X_test = tfidf_tweets_test_private"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afQpVIct8c3x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "303180c5-5730-4dcd-d255-613cbf42c1b3"
      },
      "source": [
        "print(\"The first 10 X_train: \\n\",X_train[:10])\n",
        "print(\"\\n The first 10 labels: \\n\",y_train[:10])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 10 X_train: \n",
            " [[0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " ...\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]\n",
            " [0. 0. 0. ... 0. 0. 0.]]\n",
            "\n",
            " The first 10 labels: \n",
            " [0 1 0 0 1 2 3 2 2 3]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbLKgjmP3q7R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "81f4c6dd-242c-4e9e-e44f-f9b06104d239"
      },
      "source": [
        "print(\"shape of X_train:\", X_train.shape)\n",
        "print(\"shape of y_train:\",y_train.shape)\n",
        "print(\"shape of X_val:\",X_val.shape)\n",
        "print(\"shape of y_val:\",y_val.shape)\n",
        "print(\"shape of X_test:\",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_train: (7274, 11481)\n",
            "shape of y_train: (7274,)\n",
            "shape of X_val: (1284, 11481)\n",
            "shape of y_val: (1284,)\n",
            "shape of X_test: (4064, 11481)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjyhnqtbuHgy"
      },
      "source": [
        "## Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MytJgscpuJA7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "eee62904-1b11-44fe-a580-7e58aa518371"
      },
      "source": [
        "# train model\n",
        "nb_clf = MultinomialNB()\n",
        "\n",
        "nb_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz6O4F-ZuJDO"
      },
      "source": [
        "# make prediction\n",
        "y_val_pred_nb = nb_clf.predict(X_val)\n",
        "y_tr_pred_nb = nb_clf.predict(X_train)\n",
        "y_test_pred_nb = nb_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9AfvicoULnh"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZC_c9TsvKXsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8adbabad-a86d-4bc3-c8a8-e561aeb61934"
      },
      "source": [
        "print(\"score of val set\",accuracy_score(y_val, y_val_pred_nb))\n",
        "print(\"score of train set\",accuracy_score(y_train, y_tr_pred_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score of val set 0.7320872274143302\n",
            "score of train set 0.8747594171020071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nBQc6rQRuJHT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "941c2614-863c-4532-f1b6-ae6471e37356"
      },
      "source": [
        "print('confussion matrix')\n",
        "print(confusion_matrix(y_val, y_val_pred_nb))\n",
        "\n",
        "#            Predicted\n",
        "#           0    1    2   3\n",
        "# Actual 0\n",
        "#        1\n",
        "#        2\n",
        "#        3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[238  65   7  19]\n",
            " [ 18 333   1  17]\n",
            " [  8  48 222   5]\n",
            " [ 41 111   4 147]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwvHiGW5Zccj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8f49a0a-5399-42d6-8408-e00a774daac6"
      },
      "source": [
        "print('classification report:')\n",
        "print(classification_report(y_val, y_val_pred_nb))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.72      0.75       329\n",
            "           1       0.60      0.90      0.72       369\n",
            "           2       0.95      0.78      0.86       283\n",
            "           3       0.78      0.49      0.60       303\n",
            "\n",
            "    accuracy                           0.73      1284\n",
            "   macro avg       0.78      0.72      0.73      1284\n",
            "weighted avg       0.77      0.73      0.73      1284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AqrnszOsbPL2"
      },
      "source": [
        "## Random Forest Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nx6moi8bTVp",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 76
        },
        "outputId": "b76db801-2508-4cae-c3f9-3cac355a3e2e"
      },
      "source": [
        "# Training RandomForest with 200 trees\n",
        "rf_clf = RandomForestClassifier(n_estimators=200, random_state=random_state)\n",
        "\n",
        "rf_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(n_estimators=200, random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier(n_estimators=200, random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D04biWPtctiK"
      },
      "source": [
        "# make prediction\n",
        "y_val_pred_rf = rf_clf.predict(X_val)\n",
        "y_tr_pred_rf = rf_clf.predict(X_train)\n",
        "y_test_pred_rf = rf_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UhjKgHq3dMR0"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdYn4FFBdOcx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a19eeb-2ddd-4a73-d546-99dfcff9a697"
      },
      "source": [
        "print(\"score of val set\", accuracy_score(y_val, y_val_pred_rf))\n",
        "print(\"score of train set\", accuracy_score(y_train, y_tr_pred_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score of val set 0.7484423676012462\n",
            "score of train set 0.9206763816332142\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Wq_wMMZdPDC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d648b92a-470a-40be-90c9-ecf66bc68993"
      },
      "source": [
        "print('confussion matrix')\n",
        "print(confusion_matrix(y_val, y_val_pred_rf))\n",
        "\n",
        "#            Predicted\n",
        "#           0    1    2   3\n",
        "# Actual 0\n",
        "#        1\n",
        "#        2\n",
        "#        3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[232  41  22  34]\n",
            " [ 29 282  18  40]\n",
            " [  6  26 247   4]\n",
            " [ 47  49   7 200]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYlPx2a5dPFi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f1cae16-2746-4ee7-f83e-bdb57c9a3d80"
      },
      "source": [
        "print('classification report:')\n",
        "print(classification_report(y_val, y_val_pred_rf))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.71      0.72       329\n",
            "           1       0.71      0.76      0.74       369\n",
            "           2       0.84      0.87      0.86       283\n",
            "           3       0.72      0.66      0.69       303\n",
            "\n",
            "    accuracy                           0.75      1284\n",
            "   macro avg       0.75      0.75      0.75      1284\n",
            "weighted avg       0.75      0.75      0.75      1284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xz2aY3h0-RB8"
      },
      "source": [
        "## Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QYp2_3y--QYB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "fd249961-d668-460b-d713-34b2c38cf1e2"
      },
      "source": [
        "log_clf = LogisticRegression(random_state=random_state)\n",
        "\n",
        "log_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(random_state=42)"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=42)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_oDZzTn-QYG"
      },
      "source": [
        "# make prediction\n",
        "y_val_pred_log = log_clf.predict(X_val)\n",
        "y_tr_pred_log = log_clf.predict(X_train)\n",
        "y_test_pred_log = log_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JRopJj_Q-QYI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hMP-2o---QYJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a03e547f-f34a-4892-dfac-f9cd4584a476"
      },
      "source": [
        "print(\"score of val set\", accuracy_score(y_val, y_val_pred_log))\n",
        "print(\"score of train set\", accuracy_score(y_train, y_tr_pred_log))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score of val set 0.7757009345794392\n",
            "score of train set 0.8952433324168271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nUAJQqhj-QYL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cee489df-0242-484a-f8bd-e0ad8ad29367"
      },
      "source": [
        "print('confussion matrix')\n",
        "print(confusion_matrix(y_val, y_val_pred_log))\n",
        "\n",
        "#            Predicted\n",
        "#           0    1    2   3\n",
        "# Actual 0\n",
        "#        1\n",
        "#        2\n",
        "#        3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[245  48   9  27]\n",
            " [ 21 315   8  25]\n",
            " [  9  27 242   5]\n",
            " [ 38  65   6 194]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gwHssng8-QYN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "45220b96-ea20-4de1-8219-80730665ae43"
      },
      "source": [
        "print('classification report:')\n",
        "print(classification_report(y_val, y_val_pred_log))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.74      0.76       329\n",
            "           1       0.69      0.85      0.76       369\n",
            "           2       0.91      0.86      0.88       283\n",
            "           3       0.77      0.64      0.70       303\n",
            "\n",
            "    accuracy                           0.78      1284\n",
            "   macro avg       0.79      0.77      0.78      1284\n",
            "weighted avg       0.78      0.78      0.78      1284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y3frxHcF-uxA"
      },
      "source": [
        "## LinearSVC"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsaHB7P3-uxC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 96
        },
        "outputId": "6c813624-b4f9-42f1-cf49-8d28333d5bdb"
      },
      "source": [
        "svc_clf = LinearSVC()\n",
        "\n",
        "svc_clf.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LinearSVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"‚ñ∏\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"‚ñæ\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LinearSVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LinearSVC</label><div class=\"sk-toggleable__content\"><pre>LinearSVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju2iolQY-uxF"
      },
      "source": [
        "# make prediction\n",
        "y_val_pred_svc = svc_clf.predict(X_val)\n",
        "y_tr_pred_svc = svc_clf.predict(X_train)\n",
        "y_test_pred_svc = svc_clf.predict(X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2EQ9eZvd-uxI"
      },
      "source": [
        "### Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wvVspZgu-uxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "637980ba-6c27-4047-a55d-a5644ca121bd"
      },
      "source": [
        "print(\"score of val set\", accuracy_score(y_val, y_val_pred_svc))\n",
        "print(\"score of train set\", accuracy_score(y_train, y_tr_pred_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "score of val set 0.7850467289719626\n",
            "score of train set 0.9162771514984878\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olcR87c_-uxL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40cebc20-41fb-4276-d669-8391abf072a2"
      },
      "source": [
        "print('confussion matrix')\n",
        "print(confusion_matrix(y_val, y_val_pred_svc))\n",
        "\n",
        "#            Predicted\n",
        "#           0    1    2   3\n",
        "# Actual 0\n",
        "#        1\n",
        "#        2\n",
        "#        3"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "confussion matrix\n",
            "[[252  40   4  33]\n",
            " [ 29 302   8  30]\n",
            " [  6  20 251   6]\n",
            " [ 44  49   7 203]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_JkyMhrI-uxM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e1de106-2695-468d-ad68-a48d150619f5"
      },
      "source": [
        "print('classification report:')\n",
        "print(classification_report(y_val, y_val_pred_svc))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classification report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.76      0.77      0.76       329\n",
            "           1       0.73      0.82      0.77       369\n",
            "           2       0.93      0.89      0.91       283\n",
            "           3       0.75      0.67      0.71       303\n",
            "\n",
            "    accuracy                           0.79      1284\n",
            "   macro avg       0.79      0.79      0.79      1284\n",
            "weighted avg       0.79      0.79      0.78      1284\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w6m5lFn5MtoF"
      },
      "source": [
        "## Observation\n",
        "\n",
        "From the evaluations, between the chosen 4 models, LinearSVC model gives the best accuracy score on validation sets:\n",
        "\n",
        "**0.785**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_bb_OJfiTDdB"
      },
      "source": [
        "---\n",
        "# Deep machine learning\n",
        "\n",
        "Since the best accuracy score on validation sets using Conventional models is **0.785**, the goal of deep models is to achieve a higher score.\n",
        "\n",
        "There are two main trial in this section:\n",
        "* The first trial is to build a neuron network and take the previous generated TF.IDF vectors as training data.\n",
        "\n",
        "* The second trial is to build neuron networks using embedinng layer.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pvNhlg4iTqzS"
      },
      "source": [
        "## Preparation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yvABzefWaHqG"
      },
      "source": [
        "###Convert labels to one-hot encoding vectors\n",
        "Neuron networks train most effectively when labels are one-hot encoding vectors. Thus, the training and validation labels encoded into one-hot encoding vector in this section."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZKfdJF-TqFd"
      },
      "source": [
        "# convert labels to one-hot encoding vectors:\n",
        "num_classes = len(emotions)    # number of classes\n",
        "vec_labels_train = np_utils.to_categorical(labels_train_new, num_classes)\n",
        "vec_labels_val = np_utils.to_categorical(labels_val_new, num_classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XtPLg-_4aFKB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbb4643d-4c35-4872-9709-af2c85eaf101"
      },
      "source": [
        "print(\"labels of the first 5 sentences: \")\n",
        "vec_labels_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "labels of the first 5 sentences: \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [1., 0., 0., 0.],\n",
              "       [0., 1., 0., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MT8XopeafE_d"
      },
      "source": [
        "### Set up EarlyStopping and ModelCheckpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0IS-g-0ne4zT"
      },
      "source": [
        "earlyStopping = EarlyStopping(monitor='val_loss', patience=5, verbose=1, mode='min')\n",
        "\n",
        "mcp_save = ModelCheckpoint(filepath='best_model.h5', save_best_only=True, monitor='val_loss', mode='min')\n",
        "\n",
        "reduce_lr_loss = ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=1, verbose=1, mode='min')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A_7oe5nhYYnH"
      },
      "source": [
        "### Prediction function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SHqvdOnrYX-B"
      },
      "source": [
        "def make_prediction(model, X_test):\n",
        "  y_pred = model.predict(X_test)\n",
        "  y_pred = np.argmax(y_pred, axis=1)\n",
        "  return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSIJYc-TX0hu"
      },
      "source": [
        "## First trial - NN with TF.IDF\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7ITbYby-8gFd"
      },
      "source": [
        "### Variables"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z9ROz1sAnmfC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84a07baa-8aa2-4389-fbc1-d53a5cb904a0"
      },
      "source": [
        "X_train = tfidf_tweets_train\n",
        "y_train = vec_labels_train\n",
        "\n",
        "X_val = tfidf_tweets_val\n",
        "y_val = vec_labels_val\n",
        "\n",
        "X_test = tfidf_tweets_test_public\n",
        "# X_test = tfidf_tweets_test_private\n",
        "\n",
        "print(\"X_train shape = \", X_train.shape)\n",
        "print(\"y_train shape = \", y_train.shape)\n",
        "print(\"X_val shape = \", X_val.shape)\n",
        "print(\"y_val shape = \", y_val.shape)\n",
        "print(\"X_test shape = \", X_test.shape)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train shape =  (7274, 11481)\n",
            "y_train shape =  (7274, 4)\n",
            "X_val shape =  (1284, 11481)\n",
            "y_val shape =  (1284, 4)\n",
            "X_test shape =  (4064, 11481)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3bSPbDls74O",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "087ba327-224c-475d-a290-33b465affc15"
      },
      "source": [
        "input_shape = X_train.shape[1:]\n",
        "print(\"input_shape = \", input_shape)\n",
        "\n",
        "input_dim = len(X_train[0])\n",
        "print(\"input_dim = \", input_dim)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input_shape =  (11481,)\n",
            "input_dim =  11481\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5bGAczUOd_vh"
      },
      "source": [
        "### Training model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6R7Z4Q-GbhBR"
      },
      "source": [
        "model_tfidf = Sequential()\n",
        "\n",
        "model_tfidf.add(Dense(128, activation='relu', input_dim=input_dim))\n",
        "model_tfidf.add(Dropout(0.25))\n",
        "\n",
        "model_tfidf.add(Dense(32, activation='relu'))\n",
        "model_tfidf.add(Dropout(0.25))\n",
        "\n",
        "\n",
        "model_tfidf.add(Dense(32, activation='relu'))\n",
        "model_tfidf.add(Dropout(0.25))\n",
        "\n",
        "model_tfidf.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model_tfidf.summary\n",
        "\n",
        "model_tfidf.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Am8Or4iHe3v7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fce4589-0a44-4d47-e387-8d7f363abde6"
      },
      "source": [
        "model_tfidf.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss]\n",
        "          )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "228/228 [==============================] - 8s 10ms/step - loss: 1.2013 - accuracy: 0.4644 - val_loss: 0.7348 - val_accuracy: 0.7555 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 0.5637 - accuracy: 0.8225 - val_loss: 0.6720 - val_accuracy: 0.7555 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "225/228 [============================>.] - ETA: 0s - loss: 0.3599 - accuracy: 0.8811\n",
            "Epoch 3: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "228/228 [==============================] - 1s 6ms/step - loss: 0.3613 - accuracy: 0.8807 - val_loss: 0.7177 - val_accuracy: 0.7469 - lr: 0.0010\n",
            "Epoch 4/20\n",
            "224/228 [============================>.] - ETA: 0s - loss: 0.2583 - accuracy: 0.9082\n",
            "Epoch 4: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "228/228 [==============================] - 1s 6ms/step - loss: 0.2570 - accuracy: 0.9090 - val_loss: 0.7305 - val_accuracy: 0.7531 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "216/228 [===========================>..] - ETA: 0s - loss: 0.2420 - accuracy: 0.9135\n",
            "Epoch 5: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "228/228 [==============================] - 1s 6ms/step - loss: 0.2447 - accuracy: 0.9128 - val_loss: 0.7332 - val_accuracy: 0.7539 - lr: 1.0000e-05\n",
            "Epoch 6/20\n",
            "221/228 [============================>.] - ETA: 0s - loss: 0.2426 - accuracy: 0.9118\n",
            "Epoch 6: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "228/228 [==============================] - 1s 4ms/step - loss: 0.2417 - accuracy: 0.9122 - val_loss: 0.7334 - val_accuracy: 0.7539 - lr: 1.0000e-06\n",
            "Epoch 7/20\n",
            "219/228 [===========================>..] - ETA: 0s - loss: 0.2495 - accuracy: 0.9111\n",
            "Epoch 7: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "228/228 [==============================] - 1s 5ms/step - loss: 0.2467 - accuracy: 0.9120 - val_loss: 0.7335 - val_accuracy: 0.7539 - lr: 1.0000e-07\n",
            "Epoch 7: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd07391af20>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KlF0aPzAyeHt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d3dec1b-a57b-47ae-c50a-a3725d709ac2"
      },
      "source": [
        "model_tfidf = load_model('best_model.h5')\n",
        "print('Evaluation of model_tfidf:',model_tfidf.evaluate(x=X_val, y=y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "41/41 [==============================] - 0s 3ms/step - loss: 0.6720 - accuracy: 0.7555\n",
            "Evaluation of model_tfidf: [0.6719509363174438, 0.7554517388343811]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3w7fpKAEyeH0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7a4b57f3-007a-4577-ddbe-b85a7d012ed1"
      },
      "source": [
        "y_pred_tfidf = make_prediction(model_tfidf, X_test)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "127/127 [==============================] - 0s 2ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDQ_zA3Selxe"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QHA4KALmvj2"
      },
      "source": [
        "### Observation\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XBzLKBjYoXnA"
      },
      "source": [
        "The validation accuracy is stil around 0.78\n",
        "\n",
        "**-> We can see that using NN with TF.IDF does not improve the accuracy on validation set**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KSjjLIj0Zt8y"
      },
      "source": [
        "## Second trial - NNs with embedding layer\n",
        "\n",
        "Since using the training data processed with TF.IDF method does not improve the accuracy on validation set, this section considers training NNs with the cleaned text data and using embedding layer in the NN.\n",
        "\n",
        "I also consider using a pre-trained embeding vector in this section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1XQiacRUowVu"
      },
      "source": [
        "### Convert text to vectors\n",
        "\n",
        "In order to input the cleaned text data into embeding layer of the NN, the data needs to be converted into vectors."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YzTkxSEuovze"
      },
      "source": [
        "# iterate through each sentence in the corpus and then tokenize the sentence into words\n",
        "def vectorize_text(X_train, X_val, X_test, X_test_pri):\n",
        "  from keras.preprocessing.text import Tokenizer\n",
        "  tokenizer = Tokenizer()\n",
        "  tokenizer.fit_on_texts(X_train)\n",
        "\n",
        "  word_index = tokenizer.word_index\n",
        "  vocab_length = len(word_index) + 1\n",
        "\n",
        "\n",
        "  X_train_vec = tokenizer.texts_to_sequences(X_train)\n",
        "  X_val_vec = tokenizer.texts_to_sequences(X_val)\n",
        "  X_test_vec = tokenizer.texts_to_sequences(X_test)\n",
        "  X_test_pri_vec = tokenizer.texts_to_sequences(X_test_pri)\n",
        "\n",
        "  X_train_vec_pad = pad_sequences(X_train_vec, len(tweets_train[0]), padding='post')\n",
        "  X_val_vec_pad = pad_sequences(X_val_vec, len(tweets_train[0]), padding='post')\n",
        "  X_test_vec_pad = pad_sequences(X_test_vec, len(tweets_train[0]), padding='post')\n",
        "  X_test_pri_vec_pad = pad_sequences(X_test_pri_vec, len(tweets_train[0]), padding='post')\n",
        "\n",
        "  return X_train_vec_pad, X_val_vec_pad, X_test_vec_pad, X_test_pri_vec_pad, vocab_length, word_index"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lzJScdiJnPDr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "827bbe2e-84d6-4188-df4d-4a462361f367"
      },
      "source": [
        "vec_tweets_train, vec_tweets_val, vec_tweets_test_public, vec_tweets_test_private, vocab_length, vocab = vectorize_text(processed_tweets_train_t,\n",
        "                                                                                                                        processed_tweets_val_t,\n",
        "                                                                                                                        processed_tweets_test_public_t,\n",
        "                                                                                                                        processed_tweets_test_private_t)\n",
        "\n",
        "print(\"shape of vec_tweets_train:\", vec_tweets_train.shape)\n",
        "print(\"shape of vec_tweets_val:\", vec_tweets_val.shape)\n",
        "print(\"shape of vec_tweets_test_public:\", vec_tweets_test_public.shape)\n",
        "print(\"shape of vec_tweets_test_private:\", vec_tweets_test_private.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of vec_tweets_train: (7274, 52)\n",
            "shape of vec_tweets_val: (1284, 52)\n",
            "shape of vec_tweets_test_public: (4064, 52)\n",
            "shape of vec_tweets_test_private: (4257, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH8ytxvJe5EZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9781042-d6fb-4d6d-db6c-8ad8bd2358f9"
      },
      "source": [
        "print('The first 5 labels:')\n",
        "vec_tweets_train[:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The first 5 labels:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[6111, 2317,  431,  492,   10,  256,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [   4,   17,  175,   54,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [  69,   36,  356,    1,  464,   11, 6112, 2889,  612,   56, 1149,\n",
              "        6113,    9,    1,  240,   22, 6114, 1266, 6115,   44,    6, 2890,\n",
              "           6,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 161, 1720,    7,    2, 1267,   50, 2891, 2318,  885,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0],\n",
              "       [ 174,  288, 6116,    7, 2319,    9,    1, 1268,  997, 3757,   25,\n",
              "          52,  933,   25, 6117, 6118,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0,    0,    0,    0,    0]], dtype=int32)"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z5gM_vsjW88T"
      },
      "source": [
        "### Variables\n",
        "\n",
        "For this section, I create two groups of variables for comparisions to clarify whether I preporcessed the data too much or not.\n",
        "\n",
        "*   Original variables: are from the given data *(after merging and splitting)*;\n",
        "*   Processed variables are from the processed data\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGqnTyVrjr2_"
      },
      "source": [
        "**Original variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ro_-AvlkbnH2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "449a4f68-1ead-4646-b564-e3f2e3070a0b"
      },
      "source": [
        "num_words_ori = len(vocabulary)\n",
        "tweet_length_ori = len(tweets_train_new[0])\n",
        "vocab_ori = vocabulary\n",
        "print('num_classes =', num_classes)\n",
        "print('num_words_ori =', num_words_ori)\n",
        "print('tweet_length_ori =', tweet_length_ori)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 4\n",
            "num_words_ori = 13978\n",
            "tweet_length_ori = 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yt7-v18fkAq3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f55c328-a884-40d9-b694-918418673499"
      },
      "source": [
        "X_train_ori = tweets_train_new\n",
        "y_train = np.asarray(vec_labels_train)\n",
        "\n",
        "X_val_ori = tweets_val_new\n",
        "y_val = np.asarray(vec_labels_val)\n",
        "\n",
        "X_test_ori = tweets_test_public\n",
        "# X_test_ori = tweets_test_private\n",
        "\n",
        "print(\"shape of X_train_ori:\", X_train_ori.shape)\n",
        "print(\"shape of y_train:\",y_train.shape)\n",
        "print(\"shape of X_val_ori:\",X_val_ori.shape)\n",
        "print(\"shape of y_val:\",y_val.shape)\n",
        "print(\"shape of X_test_ori:\",X_test_ori.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_train_ori: (7274, 52)\n",
            "shape of y_train: (7274, 4)\n",
            "shape of X_val_ori: (1284, 52)\n",
            "shape of y_val: (1284, 4)\n",
            "shape of X_test_ori: (4064, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_q06NnCxjrLB"
      },
      "source": [
        "**Processed variables**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AjGFJHKSinvf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03cdbb66-9c86-40dc-c37d-bb803b454bf7"
      },
      "source": [
        "num_words = vocab_length\n",
        "tweet_length = len(vec_tweets_train[0])\n",
        "vocab = vocab\n",
        "print('num_classes =', num_classes)\n",
        "print('num_words =', num_words)\n",
        "print('tweet_length =', tweet_length)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_classes = 4\n",
            "num_words = 11654\n",
            "tweet_length = 52\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q1pinWDsIEw2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4153a67a-891b-4f84-f02e-6ca9a589e006"
      },
      "source": [
        "X_train = vec_tweets_train\n",
        "y_train = np.asarray(vec_labels_train)\n",
        "\n",
        "X_val = vec_tweets_val\n",
        "y_val = np.asarray(vec_labels_val)\n",
        "\n",
        "X_test = vec_tweets_test_public\n",
        "# X_test = vec_tweets_test_private\n",
        "\n",
        "print(\"shape of X_train:\", X_train.shape)\n",
        "print(\"shape of y_train:\",y_train.shape)\n",
        "print(\"shape of X_val:\",X_val.shape)\n",
        "print(\"shape of y_val:\",y_val.shape)\n",
        "print(\"shape of X_test:\",X_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "shape of X_train: (7274, 52)\n",
            "shape of y_train: (7274, 4)\n",
            "shape of X_val: (1284, 52)\n",
            "shape of y_val: (1284, 4)\n",
            "shape of X_test: (4064, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMd018-A-KpC"
      },
      "source": [
        "### Set up GloVe Embeding vector\n",
        "\n",
        "Because this is tweets dataset, I will use 200 dimensions pre-trained-on-tweets GloVe vectors. The file can be downloaded on [GloVe website](https://nlp.stanford.edu/projects/glove/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TVezST4t-PBS"
      },
      "source": [
        "# load glove file\n",
        "emb_dict = {}\n",
        "glove_dim = 200\n",
        "glove = open('glove.twitter.27B/glove.twitter.27B.200d.txt')\n",
        "\n",
        "# add embedding vectors to emb_dict\n",
        "for line in glove:\n",
        "    values = line.split()\n",
        "    word = values[0]\n",
        "    vector = np.asarray(values[1:], dtype='float32')\n",
        "    emb_dict[word] = vector\n",
        "\n",
        "glove.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CzbWHqrry1lO"
      },
      "source": [
        "# create embedding matrix with GloVe weight\n",
        "def get_weight_matrix(num_words, vocab):\n",
        "  emb_matrix = np.zeros((num_words, glove_dim))\n",
        "\n",
        "  for w, i in vocab.items():    # only load the weight of existing words\n",
        "      if i < num_words:\n",
        "          vect = emb_dict.get(w)\n",
        "          if vect is not None:\n",
        "              emb_matrix[i] = vect\n",
        "      else:\n",
        "          break\n",
        "\n",
        "  return emb_matrix\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FX8xhD0p2M4Y"
      },
      "source": [
        "emb_matrix_ori = get_weight_matrix(num_words_ori, vocab_ori)\n",
        "\n",
        "emb_matrix = get_weight_matrix(num_words, vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4M8i1b_0ezV"
      },
      "source": [
        "embedding_vector_length = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7G56NYO02ib2"
      },
      "source": [
        "# create embedding_layer from GloVe weight\n",
        "embedding_layer_Glo_ori = Embedding(input_dim = num_words_ori,\n",
        "                            output_dim = embedding_vector_length,\n",
        "                            # embeddings_initializer=Constant(emb_matrix_ori),\n",
        "                            weights=[emb_matrix_ori],\n",
        "                            input_length=tweet_length_ori,\n",
        "                            trainable=False)\n",
        "\n",
        "embedding_layer_Glo = Embedding(input_dim = num_words,\n",
        "                            output_dim = glove_dim,\n",
        "                            # embeddings_initializer=Constant(emb_matrix),\n",
        "                            weights=[emb_matrix],\n",
        "                            input_length=tweet_length,\n",
        "                            trainable=False)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HJWlobNKu6fM"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pwq6jYZIrGgU"
      },
      "source": [
        "### NN models\n",
        "\n",
        "There are 6 models in total depeending on the training data:\n",
        "\n",
        "\n",
        "1.  Model using normal embeding layer with processed data\n",
        "2.  Model using normal embeding layer with original data\n",
        "3.  Model using GloVe embeding with processed data with `trainable = False`\n",
        "4.  Model using GloVe embeding with processed data with `trainable = True`\n",
        "5.  Model using GloVe embeding with original data with `trainable = False`\n",
        "6.  Model using GloVe embeding with original data with `trainable = True`\n",
        "\n",
        "\n",
        "**Note:** all models have the same architecture, the only difference lies on embeding weight and the training data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wZLFeg1eTSP3"
      },
      "source": [
        "#### 1 Model using normal embeding layer with processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "143Ed_9LO_xf"
      },
      "source": [
        "embedding_vector_length = 200"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L8krsNkIZ389",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52ca9cbc-74dd-4a73-f709-6be0008acb20"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_1 = Sequential()\n",
        "\n",
        "model_1.add(Embedding(input_dim = num_words,\n",
        "                    output_dim = embedding_vector_length,\n",
        "                    input_length = tweet_length))\n",
        "\n",
        "model_1.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "model_1.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Activation('relu'))\n",
        "model_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "model_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model_1.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_1.add(BatchNormalization())\n",
        "model_1.add(Activation('relu'))\n",
        "\n",
        "model_1.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_1.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_1.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_1.add(Dropout(0.25))\n",
        "\n",
        "model_1.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n",
            "WARNING:tensorflow:Layer lstm_1 will not use cuDNN kernels since it doesn't meet the criteria. It will use a generic GPU kernel as fallback when running on GPU.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     (None, 52, 200)           2330800   \n",
            "                                                                 \n",
            " bidirectional (Bidirectiona  (None, 52, 256)          336896    \n",
            " l)                                                              \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 52, 64)            82176     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 51, 64)            8256      \n",
            "                                                                 \n",
            " batch_normalization (BatchN  (None, 51, 64)           256       \n",
            " ormalization)                                                   \n",
            "                                                                 \n",
            " activation (Activation)     (None, 51, 64)            0         \n",
            "                                                                 \n",
            " max_pooling1d (MaxPooling1D  (None, 25, 64)           0         \n",
            " )                                                               \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 25, 64)            0         \n",
            "                                                                 \n",
            " conv1d_1 (Conv1D)           (None, 24, 64)            8256      \n",
            "                                                                 \n",
            " batch_normalization_1 (Batc  (None, 24, 64)           256       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_1 (Activation)   (None, 24, 64)            0         \n",
            "                                                                 \n",
            " conv1d_2 (Conv1D)           (None, 23, 32)            4128      \n",
            "                                                                 \n",
            " batch_normalization_2 (Batc  (None, 23, 32)           128       \n",
            " hNormalization)                                                 \n",
            "                                                                 \n",
            " activation_2 (Activation)   (None, 23, 32)            0         \n",
            "                                                                 \n",
            " global_max_pooling1d (Globa  (None, 32)               0         \n",
            " lMaxPooling1D)                                                  \n",
            "                                                                 \n",
            " dense (Dense)               (None, 32)                1056      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 32)                1056      \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 32)                0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 16)                528       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 4)                 68        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 2,773,860\n",
            "Trainable params: 2,773,540\n",
            "Non-trainable params: 320\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffIq3iMXTfWn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "55c91a4b-2661-46d3-9d6d-9efbf6f532a7"
      },
      "source": [
        "model_1.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss,\n",
        "                               ]\n",
        "                    )\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "228/228 [==============================] - 199s 793ms/step - loss: 1.4612 - accuracy: 0.2974 - val_loss: 1.4390 - val_accuracy: 0.2874 - lr: 0.0010\n",
            "Epoch 2/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 1.3678 - accuracy: 0.3584\n",
            "Epoch 2: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
            "228/228 [==============================] - 170s 745ms/step - loss: 1.3678 - accuracy: 0.3584 - val_loss: 1.6782 - val_accuracy: 0.3092 - lr: 0.0010\n",
            "Epoch 3/20\n",
            "228/228 [==============================] - 166s 728ms/step - loss: 1.1517 - accuracy: 0.4720 - val_loss: 1.2159 - val_accuracy: 0.4377 - lr: 1.0000e-04\n",
            "Epoch 4/20\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 1.1031 - accuracy: 0.4849 - val_loss: 1.1764 - val_accuracy: 0.4517 - lr: 1.0000e-04\n",
            "Epoch 5/20\n",
            "228/228 [==============================] - 163s 717ms/step - loss: 1.0714 - accuracy: 0.4999 - val_loss: 1.1679 - val_accuracy: 0.4564 - lr: 1.0000e-04\n",
            "Epoch 6/20\n",
            "228/228 [==============================] - 164s 720ms/step - loss: 1.0376 - accuracy: 0.5194 - val_loss: 1.1527 - val_accuracy: 0.4712 - lr: 1.0000e-04\n",
            "Epoch 7/20\n",
            "228/228 [==============================] - 165s 722ms/step - loss: 1.0051 - accuracy: 0.5635 - val_loss: 1.1375 - val_accuracy: 0.5171 - lr: 1.0000e-04\n",
            "Epoch 8/20\n",
            "228/228 [==============================] - 165s 723ms/step - loss: 0.9281 - accuracy: 0.6332 - val_loss: 1.0912 - val_accuracy: 0.5802 - lr: 1.0000e-04\n",
            "Epoch 9/20\n",
            "228/228 [==============================] - 165s 724ms/step - loss: 0.8171 - accuracy: 0.6860 - val_loss: 1.0607 - val_accuracy: 0.5888 - lr: 1.0000e-04\n",
            "Epoch 10/20\n",
            "228/228 [==============================] - 163s 713ms/step - loss: 0.7245 - accuracy: 0.7278 - val_loss: 0.9348 - val_accuracy: 0.6417 - lr: 1.0000e-04\n",
            "Epoch 11/20\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 0.6479 - accuracy: 0.7615 - val_loss: 0.9032 - val_accuracy: 0.6729 - lr: 1.0000e-04\n",
            "Epoch 12/20\n",
            "228/228 [==============================] - 163s 717ms/step - loss: 0.5886 - accuracy: 0.7994 - val_loss: 0.8861 - val_accuracy: 0.6939 - lr: 1.0000e-04\n",
            "Epoch 13/20\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 0.5320 - accuracy: 0.8276 - val_loss: 0.8729 - val_accuracy: 0.7040 - lr: 1.0000e-04\n",
            "Epoch 14/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 0.4750 - accuracy: 0.8529\n",
            "Epoch 14: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 0.4750 - accuracy: 0.8529 - val_loss: 1.0426 - val_accuracy: 0.6340 - lr: 1.0000e-04\n",
            "Epoch 15/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 0.4310 - accuracy: 0.8651\n",
            "Epoch 15: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 0.4310 - accuracy: 0.8651 - val_loss: 0.8736 - val_accuracy: 0.7002 - lr: 1.0000e-05\n",
            "Epoch 16/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 0.4243 - accuracy: 0.8686\n",
            "Epoch 16: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
            "228/228 [==============================] - 163s 718ms/step - loss: 0.4243 - accuracy: 0.8686 - val_loss: 0.8827 - val_accuracy: 0.7064 - lr: 1.0000e-06\n",
            "Epoch 17/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 0.4227 - accuracy: 0.8748\n",
            "Epoch 17: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
            "228/228 [==============================] - 163s 717ms/step - loss: 0.4227 - accuracy: 0.8748 - val_loss: 0.8836 - val_accuracy: 0.7064 - lr: 1.0000e-07\n",
            "Epoch 18/20\n",
            "228/228 [==============================] - ETA: 0s - loss: 0.4161 - accuracy: 0.8731\n",
            "Epoch 18: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
            "228/228 [==============================] - 164s 721ms/step - loss: 0.4161 - accuracy: 0.8731 - val_loss: 0.8852 - val_accuracy: 0.7064 - lr: 1.0000e-08\n",
            "Epoch 18: early stopping\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fd0e66ba260>"
            ]
          },
          "metadata": {},
          "execution_count": 80
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cpYXN--NahR8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "f057bb7d-6869-4101-8f46-1d14b0ab971f"
      },
      "source": [
        "model_1 = load_model('best_model.h5')\n",
        "print('Evaluation of model_1:',model_1.evaluate(x=X_val, y=y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-82-c105b2edbf5f>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel_1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluation of model_1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel_1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 11481), found shape=(None, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sc5Pj-M9AYd-",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 589
        },
        "outputId": "ed3498ad-a5ac-46e7-f45c-bcbbf046a51b"
      },
      "source": [
        "test1 = load_model('best_model.h5')\n",
        "print('Evaluation of model_1:',test1.evaluate(x=X_val, y=y_val))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-83-c7c0d11ae9d6>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtest1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'best_model.h5'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Evaluation of model_1:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mtest1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__test_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1852, in test_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1836, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1824, in run_step  **\n        outputs = model.test_step(data)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/training.py\", line 1788, in test_step\n        y_pred = self(x, training=False)\n    File \"/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/usr/local/lib/python3.10/dist-packages/keras/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"sequential\" is incompatible with the layer: expected shape=(None, 11481), found shape=(None, 52)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gGdNj6Q8ahSC"
      },
      "source": [
        "y_pred_1 = make_prediction(model_1,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4BCZkfJgP-Tr"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GFqsSZPrTZDL"
      },
      "source": [
        "#### 2 Model using normal embeding layer with original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APx-PFMCbPv3"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_2 = Sequential()\n",
        "\n",
        "model_2.add(Embedding(input_dim = num_words_ori,\n",
        "                    output_dim = embedding_vector_length,\n",
        "                    input_length = tweet_length_ori))\n",
        "\n",
        "model_2.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "\n",
        "model_2.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_2.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('relu'))\n",
        "model_2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model_2.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_2.add(BatchNormalization())\n",
        "model_2.add(Activation('relu'))\n",
        "\n",
        "model_2.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_2.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_2.add(Dropout(0.25))\n",
        "\n",
        "model_2.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "merhuXrjTf2p"
      },
      "source": [
        "model_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ETEmsXZTTfzo"
      },
      "source": [
        "model_2.fit(X_train_ori, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_ori, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss\n",
        "                               ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QfXsWM7A56el"
      },
      "source": [
        "model_2 = load_model('best_model.h5')\n",
        "print('Evaluation of model_2:', model_2.evaluate(x=X_val_ori, y=y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xYxvVsWpavcr"
      },
      "source": [
        "y_pred_2 = make_prediction(model_2,X_test_ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KSukR8jlZQeg"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HFV-pT9xVant"
      },
      "source": [
        "#### 3 Model using GloVe embeding with processed data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gx3pVyUssXH_"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_3_1 = Sequential()\n",
        "\n",
        "model_3_1.add(embedding_layer_Glo)\n",
        "\n",
        "model_3_1.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "\n",
        "model_3_1.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_3_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_1.add(BatchNormalization())\n",
        "model_3_1.add(Activation('relu'))\n",
        "model_3_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_3_1.add(Dropout(0.25))\n",
        "\n",
        "model_3_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_1.add(BatchNormalization())\n",
        "model_3_1.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model_3_1.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_1.add(BatchNormalization())\n",
        "model_3_1.add(Activation('relu'))\n",
        "\n",
        "model_3_1.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_3_1.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_3_1.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_3_1.add(Dropout(0.25))\n",
        "\n",
        "model_3_1.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_3_1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_3_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_3_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a33fthyJnVTK"
      },
      "source": [
        "model_3_1.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss\n",
        "                               ]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0vcGn105G5zi"
      },
      "source": [
        "model_3_1 = load_model('best_model.h5')\n",
        "print('Evaluation of model_3_1:',model_3_1.evaluate(x=X_val, y=y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DIY0JORG4qy"
      },
      "source": [
        "y_pred_3_1 = make_prediction(model_3_1,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RI1oBVuMRe1m"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhKZnaqZ8B9s"
      },
      "source": [
        "##### Set pre-trained embedding layer's trainable to True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MoqxqjbU8MUd"
      },
      "source": [
        "embedding_layer_Glo_T = Embedding(input_dim = num_words,\n",
        "                            output_dim = glove_dim,\n",
        "                            weights=[emb_matrix],\n",
        "                            input_length=tweet_length,\n",
        "                            trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rS4nPpNE0CFI"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_3_2 = Sequential()\n",
        "\n",
        "model_3_2.add(embedding_layer_Glo_T)\n",
        "\n",
        "model_3_2.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "\n",
        "model_3_2.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_3_2.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_2.add(BatchNormalization())\n",
        "model_3_2.add(Activation('relu'))\n",
        "model_3_2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_3_2.add(Dropout(0.25))\n",
        "\n",
        "model_3_2.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_2.add(BatchNormalization())\n",
        "model_3_2.add(Activation('relu'))\n",
        "\n",
        "\n",
        "model_3_2.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_3_2.add(BatchNormalization())\n",
        "model_3_2.add(Activation('relu'))\n",
        "\n",
        "model_3_2.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_3_2.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_3_2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_3_2.add(Dropout(0.25))\n",
        "\n",
        "model_3_2.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_3_2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_3_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_3_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-nwgJntaAJMA"
      },
      "source": [
        "model_3_2.fit(X_train, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss\n",
        "                               ]\n",
        "                    )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P5--wR6Z7Bsi"
      },
      "source": [
        "model_3_2 = load_model('best_model.h5')\n",
        "print('Evaluation of model_3_2:',model_3_2.evaluate(x=X_val, y=y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2XzIjKxNCULW"
      },
      "source": [
        "y_pred_3_2 = make_prediction(model_3_2,X_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RROHjaRSRjR9"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wMY3biLHn8Ae"
      },
      "source": [
        "#### 4 Model using GloVe embeding with original data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CF3Qib6Jnn5c"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_4_1 = Sequential()\n",
        "\n",
        "model_4_1.add(embedding_layer_Glo_ori)\n",
        "\n",
        "model_4_1.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "\n",
        "model_4_1.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_4_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_1.add(BatchNormalization())\n",
        "model_4_1.add(Activation('relu'))\n",
        "model_4_1.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "model_4_1.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_1.add(BatchNormalization())\n",
        "model_4_1.add(Activation('relu'))\n",
        "\n",
        "model_4_1.add(Dropout(0.25))\n",
        "\n",
        "model_4_1.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_1.add(BatchNormalization())\n",
        "model_4_1.add(Activation('relu'))\n",
        "\n",
        "model_4_1.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_4_1.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_4_1.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_4_1.add(Dropout(0.25))\n",
        "\n",
        "model_4_1.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_4_1.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_4_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_4_1.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0z6klp142WNR"
      },
      "source": [
        "model_4_1.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "93Py2cQa2WCF"
      },
      "source": [
        "model_4_1.fit(X_train_ori, y_train,\n",
        "                    epochs=20,\n",
        "                    batch_size=32,\n",
        "                    validation_data=(X_val_ori, y_val),\n",
        "                    shuffle=True,\n",
        "                    callbacks=[\n",
        "                               earlyStopping,\n",
        "                               mcp_save,\n",
        "                               reduce_lr_loss\n",
        "                               ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kz9PPgXsCCmk"
      },
      "source": [
        "model_4_1 = load_model('best_model.h5')\n",
        "print('Evaluation of model_4_1:',model_4_1.evaluate(x=X_val_ori, y=y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G52djSZxCGgF"
      },
      "source": [
        "y_pred_4_1 = make_prediction(model_4_1,X_test_ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N946Zch0CKB4"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W11p5TQtCYnY"
      },
      "source": [
        "##### Set pre-trained embedding layer's trainable to True"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bURKQdeDCYnZ"
      },
      "source": [
        "embedding_layer_Glo_ori_T = Embedding(input_dim = num_words_ori,\n",
        "                            output_dim = embedding_vector_length,\n",
        "                            weights=[emb_matrix_ori],\n",
        "                            input_length=tweet_length_ori,\n",
        "                            trainable=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RngqXL4LCYnb"
      },
      "source": [
        "from keras.layers import Activation\n",
        "\n",
        "model_4_2 = Sequential()\n",
        "\n",
        "model_4_2.add(embedding_layer_Glo_ori_T)\n",
        "\n",
        "model_4_2.add(Bidirectional(LSTM(128, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001))))\n",
        "\n",
        "model_4_2.add(LSTM(64, return_sequences=True, recurrent_dropout=0.25, dropout=0.25,  kernel_regularizer=regularizers.l2(0.0001)))\n",
        "\n",
        "model_4_2.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_2.add(BatchNormalization())\n",
        "model_4_2.add(Activation('relu'))\n",
        "model_4_2.add(MaxPooling1D(pool_size=2))\n",
        "\n",
        "\n",
        "model_4_2.add(Conv1D(filters=64,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_2.add(BatchNormalization())\n",
        "model_4_2.add(Activation('relu'))\n",
        "\n",
        "model_4_2.add(Dropout(0.25))\n",
        "\n",
        "model_4_2.add(Conv1D(filters=32,\n",
        "                 kernel_size=2,\n",
        "                 padding='valid',\n",
        "                 strides=1,\n",
        "                 kernel_regularizer=regularizers.l2(0.0001)))\n",
        "model_4_2.add(BatchNormalization())\n",
        "model_4_2.add(Activation('relu'))\n",
        "\n",
        "model_4_2.add(GlobalMaxPooling1D())\n",
        "\n",
        "model_4_2.add(Dense(32, activation='relu' , kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_4_2.add(Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "model_4_2.add(Dropout(0.25))\n",
        "\n",
        "model_4_2.add(Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.0001) ))\n",
        "\n",
        "model_4_2.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "model_4_2.compile(loss='categorical_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "model_4_2.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixkuQQKzCYne"
      },
      "source": [
        "model_4_2.fit(X_train_ori, y_train,\n",
        "                          epochs=20,\n",
        "                          batch_size=32,\n",
        "                          validation_data=(X_val_ori, y_val),\n",
        "                          shuffle=True,\n",
        "                          callbacks=[\n",
        "                                      earlyStopping,\n",
        "                                      mcp_save,\n",
        "                                      reduce_lr_loss\n",
        "                                      ])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kbffoP_SCYng"
      },
      "source": [
        "model_4_2 = load_model('best_model.h5')\n",
        "print('Evaluation of model_4_2:',model_4_2.evaluate(x=X_val_ori, y=y_val))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HlvoVvz9CYnj"
      },
      "source": [
        "y_pred_4_2 = make_prediction(model_4_2,X_test_ori)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wVXJL4SxCYnm"
      },
      "source": [
        "backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r0vvoNEgF5tO"
      },
      "source": [
        "## Observation\n",
        "\n",
        "The model trains on processed data using GloVe pre-trained embeding vetor with option `trainable = True` shows the highest validation accuracy score, at **0.799**.\n",
        "\n",
        "However, it is just slightly higher than *0.785* of LinearSVC model from Conventional machine learning.\n",
        "\n",
        "Between the Neuron Networks models, models trains on original data give lower valuation accuracy than models trains on processed data. It proves that removing special characters and `<words>` does improve the performance of the models\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N09xfojEaj9N"
      },
      "source": [
        "---\n",
        "# Discussion of Model Performance and Implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEof9NeAawh1"
      },
      "source": [
        "Comparing my final conventional ML and deep learning models:\n",
        "* The best conventional model is LinearSVC with 0785 accuracy score on validation set.\n",
        "  * This model gives 0.528 accuracy score on public test set.\n",
        "  * While this model develop good accuracy score on validation set, the score on public test set is not lower than that of the deep ML model. This shows the lack of flexibility of conventional ML.\n",
        "\n",
        "* The best deep machine learning model is the model  usinng Glove embedinng with processed data *(model 3.2)* with 0.799 accuracy score on validation set.\n",
        "  * This model gives 0.603 accuracy score on public test set and 0.64 on private test set.\n",
        "  * Although the accuracy score of this model on the validation set is just slightly better than the LinearSVC model's, the accuracy score on the public test set is 7.5% higher. This shows a better flexibility of deep ML.\n",
        "  * The accuracy score on public test set is not far apart from the accuracy score on private test set, which proves that two testing data are not very different from each other.\n",
        "\n",
        "Unfortunately, overal, the accuracy score of all models is not higher than 0.8 on validation set and even worse on test set. Personally, these score might be better if the models are feed with larger training data.\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0mcw7kqlApu"
      },
      "source": [
        "---\n",
        "# Creating csv to upload to Kaggle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d2yrFJVAapsg"
      },
      "source": [
        "**For public test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-ir805Bk9J4"
      },
      "source": [
        "# set predictions public\n",
        "predictions = y_test_pred_svc\n",
        "\n",
        "# id from 1\n",
        "id = np.arange(1, len(predictions)+1)\n",
        "\n",
        "submission = pd.DataFrame({'ID':id, 'Prediction':predictions})\n",
        "\n",
        "print(submission.head())\n",
        "\n",
        "filename = '45817006-deep.csv'\n",
        "\n",
        "submission.to_csv(filename,index=False)\n",
        "\n",
        "print('Saved file: ' + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9zLMONnnauO8"
      },
      "source": [
        "**For private test set**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7l4lunZeceM"
      },
      "source": [
        "# set predictions private\n",
        "predictions = y_pred_3_2\n",
        "\n",
        "# id from 0\n",
        "id = np.arange(0, len(predictions))\n",
        "\n",
        "submission = pd.DataFrame({'ID':id, 'Prediction':predictions})\n",
        "\n",
        "print(submission.head())\n",
        "\n",
        "filename = '45817006-private.csv'\n",
        "\n",
        "submission.to_csv(filename,index=False)\n",
        "\n",
        "print('Saved file: ' + filename)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdgyfWKwzTks"
      },
      "source": [],
      "execution_count": null,
      "outputs": []
    }
  ]
}